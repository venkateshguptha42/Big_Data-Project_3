STEP: - 1
INSTALL REQUIRED TOOLS TO PROCEED WORK
sudo apt-get install openjdk-8-jdk
wget https://dlcdn.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz
tar xvzf spark-3.1.2-bin-hadoop3.2.tgz
wget https://archive.apache.org/dist/kafka/2.0.0/kafka_2.11-2.0.0.tgz
tar xvzf kafka_2.11-2.0.0.tgz


STEP: - 2
SET PATH 
#JAVA PATH
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/
set PATH="$PATH:JAVA_HOME/bin"
export HADOOP_HOME=/home/usr/hadoop-2.7.0
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
#spark path
export SPARK_HOME=/home/ubuntu/spark-3.1.2-bin-hadoop3.2
export PATH=$PATH:$SPARK_HOME/bin



STEP: - 3
FOLLOW THIS LINK INSTALL JUPYTER NOTEBOOK ON UBUNTU
https://www.digitalocean.com/community/tutorials/how-to-set-up-jupyter-notebook-with-python-3-on-ubuntu-20-04-and-connect-via-ssh-tunneling



STEP: - 4
GOTO KAFKA DIRECTORY AND RUN ZOOKEEPER AND KAFKA SERVER
cd kafka_2.11-2.0.0/
bin/zookeeper-server-start.sh config/zookeeper.properties
bin/kafka-server-start.sh config/server.properties

STEP: - 5
CREATE A TOPIC project3 WITH REPLICATION FACTOR 1 AND PARTITION 1
bin/kafka-topics.sh --create --zookeeper localhost:2181 --topic project3 --replication-factor 1 --partitions 1


STEP: - 6
CREATE A producer.py FILE TO FETCH DATA FROM API AND PASS TO TOPIC project3
 1)CREATE ACCOUNT ON api.tiingo.com
   https://api.tiingo.com/

 2)GOTO DOCUMENTATION SECTION AND COLLECT YOUR API KEY
 
 3)COLLECT FOREX DATA API FROM REST SECTION

 4)SCROLL DOWN AND COLLECT YOUR API FROM EXAMPLES SECTION
